# Z028_Project : Documentation Technique

## Vue d'ensemble m√©tier
- **Objectif** : Trouver la pire/meilleur route de process du debut jusqu'au PT intermediare
- **Techno** : [Z028]
- **Mesures de succ√®s** : Validation metier + reproductibilit√©e 

## Architecture technique
- **Technologies** : Spotfire, python, Databricks, pySpark, SQL
- **Ressources cluster** : [Voir Section Driver](#DriverNode)




# √âtat de l'Art : Optimisation des Routes de Process

## 1. Probl√©matique et Contexte 

### 1.1 D√©finition du probl√®me
L'optimisation des routes de processus (de semi-conducteurs) vise √† identifier les s√©quences d'√©quipements et d'√©tapes qui maximisent le rendement (yield) et et par consequent minimisent les d√©fauts. Une "route" repr√©sente le chemin exact qu'un lot/wafer suit √† travers les diff√©rentes etapes de fabrication.

### 1.2 Enjeux industriels
Dans le cadre de la technologie Z028 au cours de la route jusqu'au PT intermediaire on retrouve:
- **Complexit√© des fabs** : 134 op√©rations, 222 √©tapes, 1 a 5 √©quipements par √©tape
- **Impact √©conomique** : 1% √† 2% d'am√©lioration du yield serait non negligable
- **Variabilit√© √©quipements** : Performances diff√©rentes selon l'√©quipement choisi pour chaque √©tape
- **Contraintes temps r√©el** : D√©cisions de routage n√©cessaires en continu

## 2. Approches Algorithmiques pour l'Optimisation de Routes

### 2.1 Approches de Data Mining

#### 2.1.1 R√®gles d'Association (Approche retenue)
**Principe** : Identifier les patterns fr√©quents entre √©quipements et r√©sultats qualit√©.

APRIORI : "Si ETCH-XXX01 ET LITHO-XXX2 alors 89% chance d√©faut"
‚Üí Explication claire et actionnable

FP-Growth : R√©sultat identique mais processus "bo√Æte noire"  
‚Üí Plus difficile √† expliquer aux experts m√©tier

Volume Donn√©es vs Performance R√©elle
l'approche fen√™tre glissante 12 semaines change la donne :
|Algorithme|Dataset Complet (50M)|Fen√™tre 12 sem (~4M)|Verdict|
|----------|---------------------|--------------------|-------|
|APRIORI|Lent (~45+ min)|Acceptable (~4.2 min)|Optimal|
|FP-Growth|Rapide (~12 min)|Tr√®s rapide (~1.8 min)|Excessif|

**Algorithmes principaux** :
- **APRIORI** (Agrawal & Srikant, 1994)
  - ‚ÜóÔ∏è Avantages : Simplicit√©, interpr√©tabilit√© des r√®gles
  - ‚ÜóÔ∏è Adapt√© : Donn√©es cat√©goriques (√©quipements), relation claire cause-effet
  - ‚ùå Limitations : Performance sur gros volumes, scan multiple base de donn√©es

- **FP-Growth** (Jiawei Han, Jian Pei, and Yiwen Yin, 2000)
  - ‚ÜóÔ∏è Avantages : Performance sup√©rieure, un seul scan base de donn√©es
  - ‚ÜóÔ∏è Adapt√© : Gros volumes manufacturing data
  - ‚ùå Limitations : Consommation m√©moire, moins intuitif

- **Prefix Span** (Jian Pei, Jiawei Han ,Behzad Mortazavi-Asl et Helen Pinto 2001)
  - ‚ÜóÔ∏è Avantages : Prise en compte s√©quences temporelles
  - ‚ÜóÔ∏è Adapt√© : Routes s√©quentielles dans manufacturing
  - ‚ùå Limitations : Complexit√© algorithmique √©lev√©e


#### 2.1.2 Market Basket Analysis Adapt√©
**Principe** : Transposition des techniques retail vers manufacturing.
- "Produits" = √âquipements utilis√©s
- "Transactions" = Lots de wafers
- "R√®gles" = Si √©quipement A alors probabilit√© Wafer BAD √©lev√©e

### 2.2 Approches Machine Learning

#### 2.2.1 Apprentissage Supervis√© sur Donn√©es Continues
**Algorithmes test√©s** :
- **Random Forest** : Robuste aux outliers, importance variables
- **Gradient Boosting** : Performance √©lev√©e, gestion de la non-lin√©arit√©s
- **SVM** : Efficace pour dimensions √©lev√©es

**Limitations identifi√©es** :
- Variables continues (temp√©ratures, pressions) moins discriminantes que choix √©quipements
- Perte d'information causale directe √©quipement‚Üíd√©faut
- Complexit√© interpr√©tation pour experts manufacturing
- Dimensionalit√© trop √©lev√©e

#### 2.2.2 Apprentissage Supervis√© sur Donn√©es Cat√©goriques
**Algorithmes test√©s** :
- **R√©gression Logistique** : Baseline interpretable
- **R√©gression Binomiale N√©gative** : Gestion de la surdispersion
- **Classification Naive Bayes** : Rapide, requiert peu de parametres

**Avantages** :
- Probabilit√©s pr√©diction directement utilisables
- Variables cat√©goriques = √©quipements (mapping naturel)

**Limitations** :
- Hypoth√®ses statistiques forte (ind√©pendance, distribution)
- Difficult√© capture interactions complexes √©quipements
- Dimensionalit√© trop √©lev√©e

#### 2.2.3 Deep Learning / R√©seaux de Neurones
**Approches envisag√©es** :
- **LSTM** : S√©quences temporelles de routes
- **CNN** : Patterns spatiaux sur wafers

**Raisons rejet** :
- "Trop de combinaisons pour l'algorithme" ‚Üí Explosion combinatoire
- 134 op√©rations √ó moyens 3-4 √©quipements/op√©ration = ~10^200 routes possibles
- Manque donn√©es √©tiquet√©es pour entra√Ænement deep learning
- Complexit√© d√©ploiement et maintenance en production

### 2.3 M√©thodes d'Optimisation Combinatoire

#### 2.3.1 Algorithmes G√©n√©tiques
- **Principe** : √âvolution d'une population de routes compl√®tes vers l'optimum yield par s√©lection, croisement et mutation successives. Chaque route (chromosome) repr√©sente une s√©quence compl√®te d'√©quipements pour les 134 op√©rations.
- **Applications** : Optimisation simultan√©e de s√©quences compl√®tes d'√©quipements (Kumar et al., 2006).
- **Limitations** : Explosion combinatoire, Solutions optimales sans justification causale

## 3. Techniques de Validation Routes Manufacturing

### 3.1 Validation (Approche retenue)
**Principe** : Comparaison performance routes identifi√©es sur donn√©es historiques.

**M√©thode** :
- R√©cup√©ration wafers ayant suivi exactement la "golden/worst route"
- Comparaison taux GOOD/BAD vs wafers routes alternatives
- Test significativit√© statistique (Chi-2, Fisher exact test)

**Avantages** :
- Donn√©es r√©elles, repr√©sentatives dans les conditions de production
- Validation robuste si volume suffisant
- Interpr√©tation directe pour experts m√©tier

### 3.3 Validation Exp√©rimentale
- **Principe** : Test contr√¥l√© routes identifi√©es sur lots d√©di√©s.
- **Avantages** : Validation d√©finitive, conditions r√©elles
- **Limitations** : Co√ªt √©lev√©, risque production, d√©lais longs

### 3.4 Cross-Validation Temporelle
- **Principe** : Entra√Ænement sur p√©riode N, validation p√©riode N+1.
- **Application** : Fen√™tre glissante 12 semaines avec validation 4 semaines suivantes
- **Robustesse** : D√©tection d√©rive performance √©quipements

## 4. Comparaison et Justification Choix Techniques

### 4.1 Matrice de D√©cision

| Crit√®re | R√®gles Association | ML Supervis√© | Deep Learning | Optimisation Combinatoire |
|:---------:|:-------------------:|:--------------:|:---------------:|:--------------:|
| **Interpr√©tabilit√©** |  üü©Excellente | üü®Moyenne |  üü•Faible | üü®Moyenne |
| **Performance** | üü®Moyenne |üü©Bonne |üü©Excellente | üü©Bonne |
| **Temps d√©veloppement** |üü©Court | üü®Moyen |  üü•Long | üü•Long |
| **Robustesse donn√©es** |üü©Bonne | üü®Moyenne |  üü•Faible |üü© Bonne |
| **D√©ploiement prod** |üü©Simple | üü®Moyen | üü•Complexe | üü®Moyen |
| **Expertise requise** | üü®Moyenne |üü©Standard | üü•√âlev√©e | üü•√âlev√©e |

### 4.2 Justification Choix Final

**R√®gles d'Association (APRIORI) retenues pour** :
- **Interpr√©tabilit√© essentielle** : Les experts m√©tier doivent pouvoir comprendre facilement les recommandations d‚Äô√©quipements.
- **Donn√©es adapt√©es** : Les variables cat√©goriques (types d‚Äô√©quipements) sont naturellement compatibles avec cet algorithme.
- **Validation simple** : Les r√®gels g√©n√©r√©es sont facilement v√©rifiable √† partir des donn√©es historiques 
- **D√©ploiement rapide** : L‚Äôalgorithme est simple √† mettre en ≈ìuvre et √† maintenir.

**Machine Learning √©cart√© pour** :
- La complexit√© d'interpr√©tation est trop √©lev√©e pour une prise de d√©cision en production.
- Le gain de performance est insuffisant face au co√ªt de d√©veloppement et de maintenance.
- Risque important de surapprentissage (overfitting) d√ª au bruit pr√©sent dans les donn√©es de fabrication.

**Deep Learning √©cart√© pour** :
- Explosion combinatoire li√©e au nombre tr√®s √©lev√© de routes possibles.
- Manque donn√©es (wafer) en production pour un apprentissage efficace.
- Complexit√© importante en termes d‚Äôinfrastructure et d‚Äôexpertise n√©cessaire.

## 6. Perspectives et Am√©liorations Futures

### 6.1 Hybridation des approches
- Combinaison des r√®gles d'association avec des m√©thodes ML pour am√©liorer la pr√©cision et la robustesse des recommandations.

### 6.2 Temps R√©el et Streaming
- Adaptation Kafka pour donn√©es √©quipements en temps r√©el


## Impl√©mentation code d√©taill√©

---
Pipeline Unity Catalog
---
<img width="1615" height="765" alt="image" src="https://github.com/user-attachments/assets/dddd34db-a18e-42af-b4d7-e13d26724eeb" />


---

#  Job et Pipeline Databricks

## **Vue d'ensemble du Job**

###  **Principe cl√© :**
- **Un seul notebook** ‚Üí Deux comportements diff√©rents
- **Param√®tre `type_route`** ‚Üí D√©termine le flux de donn√©es
- **Logique conditionnelle** ‚Üí `"good"` vs `"bad"` routes
- **Planification** ‚Üí Execution par p√©riode.

---


| Phase | Processus | Dur√©e |
|-------|-----------|--------|
| **Phase 1** | Data Prep | 6 min |
| **Phase 2** | APRIORI | 56 min |
| **Phase 3** | Validation | 30 sec |


# **Job Principal : `PT_Z028_Worst_Route`**

## Cluster Z028_Job_Cluster
<a id="DriverNode"></a>
## Configuration des Nodes

<table>
<tr>
<td width="50%" align="center">


### **Driver Node**
**Type :** Standard_D5s_v2
**RAM :** 112 GB
**Cores :** 16
**Quantit√© :** 1

</td>
<td width="50%" align="center">

### **Worker Nodes**
**Type :** Standard_D4ds_v5  
**RAM :** 64 GB par node
**Cores :** 4 par node
**Quantit√© :** 8 (Spot instances)

*Les Spot Instances dans Databricks sont des machines virtuelles √† prix r√©duit, mais avec moins de garanties de disponibilit√©.*
</td>
</tr>
</table>

## Ressources Totales

<div align="center">

| **RAM Total** | **Cores Total** | **Nodes Total** |
|:----------------:|:------------------:|:-------------------:|
| **128-384 GB** | **32-96 Cores** | **6 Nodes** |

---

### **Performance**

| T√¢che | Dur√©e | Notes |
|:-------:|:-------:|:-------:|
| **Data_Preparation** | 10 min | Traitement Unity Catalog |
| **AR_BAD/GOOD** | 46 min | APRIORI fen√™tre glissante |
| **Validation** | 6 min | Tests statistiques |
| **Total Pipeline** | **Auto-scaling** |  |

### **Orchestration & D√©pendances**

```mermaid
graph TD
    A[Data_Preparation] --> B[AR_BAD]
    A --> C[AR_GOOD] 
    B --> D[AR_BAD_VALIDATION]
    C --> E[AR_GOOD_VALIDATION]
    
    style A fill:#667eea
    style B fill:#f093fb  
    style C fill:#f093fb
    style D fill:#4facfe
    style E fill:#4facfe
```
</div>

### Planification
|**Fr√©quence** |**D√©clencheur**|**Timeout**|
|---------------------------------------|------------------------|---------------------|
| Hebdomadaire (chaque lundi 02:00 UTC) | Cron `58 30 4 ? * Mon` | 2h maximum par job  |


### Avantages Architecture Databricks

####  R√©utilisabilit√© maximale

- **M√™me notebook** `AR_FAMILIES_EQPT`  
- **Param√®tre** `type_route` change le comportement  
- **DRY Principle** respect√©  

####  Parall√©lisation intelligente

- **AR_BAD** et **AR_GOOD** en parall√®le  
- **Validation** en s√©quence pour coh√©rence  
- **Optimisation ressources** automatique  


####  Monitoring int√©gr√©

- **M√©triques temps r√©el** par t√¢che  
- **Notifications email** en cas d'√©chec  
- **Logs centralis√©s** pour debug  

---
####  Scalabilit√©


|**Auto-scaling cluster** |**Photon engine**|**Adaptive Query Execution**|
|:---------------------:|:-----------------------:|:--------------:|
|  selon la charge  | pour performance SQL | optimis√© |


---


## **Principe de Param√©trage**

### **Notebook unique : `AR_FAMILIES_EQPT`**

| Param√®tre | Valeur | Comportement |
|:------------:|:--------:|:-------------------------------:|
| `type_route` | `"good"` | Lit/√âcrit dans **Golden Route** |
| `type_route` | `"bad"` | Lit/√âcrit dans **Worst Route** |

### **Logique dynamique dans le code :**
```python
# Dans le notebook AR_FAMILIES_EQPT
type_route = dbutils.widgets.get("type_route")

# Pour import
df_EQPT_spark = spark.sql(f"""
    SELECT *
    FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_input_{type_route.lower()}_for_ar
    WHERE T84_TEST_DATE BETWEEN DATE_SUB(CURRENT_DATE(), 365) AND CURRENT_DATE()
""")
# Et export
    create_or_update_table(spark.createDataFrame(sparkfinal_merged_df),
    f"mds_prod_gold_experiment.datasciences_dev.pt_z028_ar_{type_route.lower()}_route_results")
```

---

## **Avantages de cette approche**

### **R√©utilisabilit√©**

- **Un seul code source** √† maintenir
- **Logique m√©tier identique** pour les deux cas
- **√âvite la duplication** de code

### **Maintenabilit√©**

- **Changements centralis√©s** dans un seul notebook
- **Coh√©rence garantie** entre les deux flux
- **Tests simplifi√©s**

### **Flexibilit√©**
- **Facilement extensible** (ajout de nouveaux types)
- **Configuration par param√®tres**
- **Orchestration Databricks native**

---



</div>


# Phase 1 : DATA_PREP.py - Rapport d'√©tat des lieux

## Vue d'ensemble

Le script `DATA_PREP.py` constitue la phase de pr√©paration des donn√©es du projet Z028. Il traite les donn√©es brutes du PT intermediaire pour produire les tables n√©cessaires √† l'analyse des r√®gles d'association.

*Note technique : Une version parall√®le de ce script existe avec des clauses WHERE √©tendues √† 365 jours (au lieu des filtres standards). Cette version a servi √† l'initialisation initiale des tables de r√©f√©rence avec un historique complet d'une ann√©e de donn√©es de production.*

### 1. Extraction SQL depuis Unity Catalog

#### LOT_LIST_INFORMATION_DF - Liste des lots √©ligibles
```sql
SELECT pt_kdf_lot_number AS LOT, 
       pt_kdf_cam_location AS LOCATION, 
       pt_kdf_product_code AS PRODUCT,
       pt_kdf_test_start_datetime AS START_DATE,
       pt_kdf_test_end_datetime AS END_DATE,
       pt_kdf_spec_name AS SPEC_NAME,
       pt_kdf_spec_version AS SPEC_VERSION

FROM sem1.pt_kdf_lot_normalized 
WHERE pt_kdf_cam_location = 'M2SICN-ADT02' 
  AND fab_name = 'CROLLES 300'
  AND LEFT(pt_kdf_product_code, 5) = 'KVB98'
  AND pt_kdf_test_end_datetime >= DATE_SUB(CURRENT_DATE(), 7)
  AND length(pt_kdf_lot_number) <= 7
```
**Filtres appliqu√©s** :
- **Localisation** : M2SICN-ADT02 (√©quipement de test sp√©cifique)
- **Fab** : CROLLES 300 uniquement
- **Produit** : Code produit commen√ßant par 'KVB98' (technologie Z028)
- **P√©riode** : 365 derniers jours
- **Format lot** : Maximum 7 caract√®res

#### df_parameter_info - Donn√©es des param√®tres
```sql
SELECT
    pt_kdf_lot_number AS LOT,
    pt_kdf_cam_location AS T84_LOCATION,
    pt_kdf_parameter_id AS PARAMETER,
    pt_kdf_parameter_value AS PARAMETER_VALUE,
    pt_kdf_test_start_datetime AS START_DATE,
    pt_kdf_test_end_datetime AS END_DATE,
    pt_kdf_wafer_number AS WAFER,
    tech_lz_folder_source_id AS FAB,
    pt_kdf_spec_name AS SPEC_NAME,
    pt_kdf_spec_version AS SPEC_VERSION,
    pt_kdf_site_name AS SITE_NUMBER,
    pt_kdf_site_is_last_pattern AS IS_LAST_PATTERN,
    MAX(pt_kdf_test_end_datetime) OVER (PARTITION BY pt_kdf_lot_number) AS MAX_TEST_DATE

FROM sem1.pt_kdf_parameter_normalized

WHERE pt_kdf_cam_location = 'M2SICN-ADT02' 
    AND fab_name = 'CROLLES 300' 
    AND pt_kdf_test_end_datetime >= DATE_SUB(CURRENT_DATE(), 7)
    AND length(pt_kdf_lot_number) <= 7
    AND pt_kdf_lot_number IN (SELECT LOT FROM LOT_LIST_INFORMATION_DF)
    AND pt_kdf_parameter_id IN (SELECT PARAMETER FROM df_PTM2_param_family_Parameter)
```
**Optimisations SQL** :
- **Window function** : MAX(test_end_datetime) OVER (PARTITION BY lot) pour identifier le dernier test
- **Jointure implicite** : IN clause avec LOT_LIST_INFORMATION_DF 
- **Filtrage param√®tres** : Seulement les param√®tres d√©finis dans df_PTM2_param_family_Parameter

####  df_Value_info - Limites et sp√©cifications
```sql
SELECT
    pt_klf_spec_name AS SPEC_NAME,
    pt_klf_spec_version AS SPEC_VERSION,
    pt_klf_parameter_id AS PARAMETER,
    pt_klf_validity_limit_lower_bound AS LVL,
    pt_klf_validity_limit_upper_bound AS UVL,
    pt_klf_spec_limit_lower_bound AS LSL,
    pt_klf_spec_limit_upper_bound AS USL,
    pt_klf_parameter_category AS PARAMETER_TYPE,
    pt_klf_parameter_target AS PARAMETER_TARGET

FROM sem1.pt_klf_normalized
    
WHERE
    pt_klf_parameter_id in (SELECT PARAMETER FROM df_PTM2_param_family_Parameter)
    AND (pt_klf_parameter_category in ('GY', 'GR', 'KR', 'KY'))
    AND pt_klf_spec_name = "C28SOIM2SICN"
```
**Limites d√©finies** :
- **LVL/UVL** : limites de validit√©
- **LSL/USL** :limites de sp√©cification
- **Cat√©gories** : GY, GR, KR, KY (types de param√®tres qualit√©)
- **Spec** : C28SOIM2SICN 

#### df_lot_history - Historique des √©quipements
```sql
select 
  leh_fe_std_lot_id as LOT
  ,leh_fe_std_operation_name as OPERATION
  ,leh_fe_std_operation_description as OPERATION_DESCRIPTION
  ,leh_fe_std_step_name as STEP
  ,leh_fe_std_equipment_id as EQUIPMENT
  ,leh_fe_std_lot_step_start_datetime as STEP_START_DATE
  ,leh_fe_std_lot_step_end_datetime as STEP_END_DATE
  ,leh_fe_std_mes_product_name as PRODUCT
  ,leh_fe_std_route_name as ROUTE
  ,leh_fe_std_recipe_id as RECIPE_ID
from publication.v_leh_fe_std_normalized
where 
  leh_fe_std_route_name = 'Z028RR_14KLR_34LS_10M'
  AND leh_fe_std_lot_id IN (SELECT LOT FROM LOT_LIST_INFORMATION_DF)
  AND SUBSTR(leh_fe_std_equipment_id, 1, 1) <> 'X'
  AND INSTR(leh_fe_std_step_name, 'MEAS') = 0
```
**Filtres route** :
- **Route sp√©cifique** : Z028RR_14KLR_34LS_10M (route de r√©f√©rence Z028)
- **√âquipements valides** : Exclusion des √©quipements commen√ßant par 'X'
- **√âtapes process** : Exclusion des √©tapes de mesure ('MEAS')

### 2. Fichiers CSV de r√©f√©rence
- **Z028_DEFAULT_PROCESS_ROUTE.csv** : Route de processus par d√©faut (s√©parateur `;`)
- **Df_Family_Ref.csv** : R√©f√©rentiel des familles de param√®tres (s√©parateur `;`)

## Transformations principales

### 1. Calcul des rendements
- Jointure donn√©es test + sp√©cifications
- Calcul OOV/OOS par param√®tre ‚Üí Yield par famille
- Pivot des familles de param√®tres en colonnes

### 2. Traitement des √©quipements
- Filtrage des √©tapes avec √©quipements variables uniquement
- Calcul de l'ordre des √©tapes et rang des op√©rations
- Encodage cat√©goriel des combinaisons STEP-EQUIPMENT

### 3. Classification GOOD/BAD
- Application des seuils m√©tier par famille (ex: CONTACT < 0.98 ‚Üí BAD)
- Agr√©gation au niveau LOGICAL_ID + OPERATION + STEP

## Outputs
Deux tables stocker dans :
  ***mds_prod_gold_experiment.datasciences_dev***
- **pt_z028_input_bad_for_ar** : Table avec indicateur BAD
- **pt_z028_input_good_for_ar** : Table avec indicateur GOOD (inverse)

**Structure finale** : 1 ligne = 1 lot + 1 √©tape + m√©triques yield + classification + √©quipements encod√©s

‚Üí  **Pr√™t pour l'analyse des r√®gles d'association** dans AR_BAD.py


# Phase 2 : AR_FAMMILLIES_EQPT.py - Analyse des R√®gles d'Association

##  Objectif
Identifier les √©quipements probl√©matiques par famille de param√®tres en utilisant l'algorithme APRIORI sur des fen√™tres glissantes de 12 semaines.

## Donn√©es d'entr√©e
- **pt_z028_input_bad_for_ar** : Table de sortie de Data_Prep.py, dataset avec encodage √©quipements + indicateur BAD
- **Df_Family_Ref.csv** : R√©f√©rentiel familles de param√®tres

## Pipeline principal

### 1. Pr√©paration des donn√©es
- **Optimisation m√©moire** : Conversion dtypes (downcast integers/floats, cat√©gorisation strings)
- **Fen√™tres glissantes** : D√©coupage en p√©riodes de 12 semaines avec d√©calage hebdomadaire
- **Filtrage par famille** : S√©lection des √©tapes pertinentes selon le r√©f√©rentiel

### 2. Analyse APRIORI par √©tape
Pour chaque (OPERATION, STEP) :
- **Encodage** : Colonnes `STEP_EQPT_[STEP]-[EQUIPMENT]` + `BAD`
- **Filtrage fr√©quence** : Garder √©quipements pr√©sents >5% du temps
- **APRIORI** : Recherche itemsets fr√©quents (min_support=0.1)
- **R√®gles d'association** : Calcul confidence, lift, support
- **Filtrage cibl√©** : R√®gles avec cons√©quent = `BAD` uniquement

### 3. Scoring et ranking
- **Score composite** : `confidence √ó lift √ó support`
- **Ranking** : Classement des √©quipements par score d√©croissant
- **Fen√™tre glissante** : Application sur toutes les semaines

### 4. Agr√©gation temporelle
- **Pivot** : Semaines en colonnes, scores en valeurs
- **Ranking final** : Rang de chaque √©quipement par semaine et par √©tape


## Output
Deux tables stocker dans :
***mds_prod_gold_experiment.datasciences_dev***

- **pt_z028_ar_bad_route_results** : Resultats des regles d'associations pour chaque famille a travers les semaines.
- **pt_z028_ar_good_route_results** : Resultats des regles d'associations pour chaque famille a travers les semaines.
- **Structure** : FAMILY | OPERATION | STEP | EQPT | week_0 | week_1 | ... | week_n
- **Valeurs** : Rang de l'√©quipement (1 = le plus probl√©matique)

##  R√©sultat m√©tier
**Identification des √©quipements les plus corr√©l√©s aux d√©fauts par famille**, avec une √©volution temporelle pour d√©tecter les d√©rives.

‚Üí **Pr√™t pour la validation** dans VALIDATION_AR_FAMILLIES.py

# Phase 3 : VALIDATION_AR_FAMILIES - Validation des Routes avec Scoring Pond√©r√©

## Objectif
Valider statistiquement les routes identifi√©es comme probl√©matiques ou bonnes dans la Phase 2 en utilisant un **syst√®me de scoring pond√©r√©** qui privil√©gie la r√©cence et la continuit√© des probl√®mes, puis comparer les performances r√©elles des wafers ayant suivi ces √©quipements.

##  √âvolution majeure : Scoring pond√©r√© temporel

### Principe du nouveau syst√®me
Au lieu d'une simple somme des occurrences, le syst√®me calcule un **score composite** bas√© sur :
- **50% R√©cence** : Les probl√®mes r√©cents sont prioritaires (d√©croissance exponentielle)
- **30% Continuit√©** : Les s√©quences cons√©cutives sont valoris√©es
- **20% Persistance** : Le nombre total d'apparitions compte aussi

### Justification m√©tier
- **Probl√®me r√©solu** : Un √©quipement probl√©matique il y a 6 mois (tres certainement corrig√© depuis) ne doit pas √™tre prioritaire sur un equipement probl√©matique r√©cent
- **Probl√®me √©mergent** : Un √©quipement devenant probl√©matique r√©cemment doit √™tre d√©tect√© rapidement
- **Pattern sporadique vs continu** : Un probl√®me continu est plus critique qu'un probl√®me intermittent (Drift)

## Param√©trage dynamique

### Param√®tres de scoring
```python
use_weighted_scoring = True     # Active le scoring pond√©r√©
recency_weight = 0.5           # 50% d'importance pour la r√©cence
continuity_weight = 0.3        # 30% d'importance pour la continuit√©
# 20% restant automatiquement allou√© √† la persistance
```

## Donn√©es d'entr√©e

### 1. Donn√©es √©quipements (Fen√™tre 365 jours)
```python
df_EQPT_spark = spark.sql(f"""
    SELECT *
    FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_input_{type_route.lower()}_for_ar
    WHERE T84_TEST_DATE BETWEEN DATE_SUB(CURRENT_DATE(), 365) AND CURRENT_DATE()
""")
```

### 2. R√©sultats AR les plus r√©cents
```python
df_ar_result = spark.sql(f"""
    SELECT * 
    FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_ar_{type_route.lower()}_route_results 
    WHERE Processed_Date_Job = ( 
        SELECT MAX(Processed_Date_Job) FROM ... 
    )
""")
```

## Pipeline de validation

### 1. Fonctions de scoring

#### `calculate_weighted_score()` - Calcul du score pond√©r√©
```python
def calculate_weighted_score(row, week_columns, recency_weight=0.7, continuity_weight=0.2):
    """
    Composantes du score :
    1. Score de r√©cence : D√©croissance exponentielle (demi-vie = 10 semaines)
    2. Score de continuit√© : Bonus quadratique pour s√©quences cons√©cutives
    3. Score de persistance : Nombre total d'apparitions normalis√©
    4. P√©nalit√© gaps : R√©duction pour patterns sporadiques
    """
```

**D√©croissance temporelle** :
- Semaine 40 (actuelle) : poids = 100%
- Semaine 30 (-10 sem) : poids ‚âà 50%
- Semaine 20 (-20 sem) : poids ‚âà 25%
- Semaine 10 (-30 sem) : poids ‚âà 12.5%
- Semaine 1 (-39 sem) : poids ‚âà 6%

#### `analyze_continuity_patterns()` - Analyse des patterns
```python
def analyze_continuity_patterns(row, week_columns):
    """
    Classification des patterns :
    - 'strong_continuous' : ‚â•6 semaines cons√©cutives
    - 'moderate_continuous' : ‚â•3 semaines cons√©cutives
    - 'sporadic' : "Grandes" interruptions (>4 semaines)
    - 'intermittent' : Apparitions espac√©es r√©guli√®res
    """
```

### 2. Fonction `validate_routes`

#### Param√®tres principaux
```python
df_validation = validate_routes(
    df_ar_result,           # R√©sultats AR de la phase 2
    df_EQPT_spark,         # Donn√©es √©quipements sur 365j
    type_route,            # "BAD" ou "GOOD"
    min_sum=6,             # Seuil minimum du score
    use_weighted_scoring=True,  # Active le scoring pond√©r√©
    recency_weight=0.5,         # 50% pour la r√©cence
    continuity_weight=0.3       # 30% pour la continuit√©
)
```

### 3. Processus de validation d√©taill√©

#### √âtape 1 : Calcul des scores pond√©r√©s
```python
# Pour chaque √©quipement, calcul du score composite
df_ar['WEIGHTED_SCORE'] = df_ar.apply(
    lambda row: calculate_weighted_score(row, week_columns, 0.5, 0.3), 
    axis=1
)

# Ajout des m√©triques de continuit√©
df_ar['continuity_pattern'] = ...      # Type de pattern d√©tect√©
df_ar['max_consecutive_weeks'] = ...   # Plus longue s√©quence
```

#### √âtape 2 : S√©lection des worst/best routes

**Nouveau crit√®re** : Utilisation de `WEIGHTED_SCORE`

1. **Filtrage score minimum** : `df[df['WEIGHTED_SCORE'] >= min_sum]`
2. **S√©lection par OP_STEP** : √âquipement avec le score pond√©r√© maximum
3. **Ajustement par taille de famille** :
   - Petite (‚â§8 √©tapes) : 100% conserv√©
   - Moyenne (‚â§15 √©tapes) : 60% conserv√©
   - Grande (>15 √©tapes) : 30% conserv√© (max 10)

#### √âtape 3 : Affichage enrichi des routes

```
Traitement famille : CONTACT
Utilisation du scoring pond√©r√© avec bonus de continuit√©
   Poids r√©cence: 50%, continuit√©: 30%, persistance: 20%
   Score moyen (simple) : 8.43
   Score moyen (pond√©r√©) : 24.67

Top 5 √©quipements par score pond√©r√© :
  ‚Ä¢ O_STRIP|STEP_DRY -> SGAMA04
    Score: 45.2 (simple: 12)
    Pattern: strong_continuous, Max cons√©cutif: 8 semaines
  ‚Ä¢ O_DEP_HK|DEP_HK -> TCENT11
    Score: 38.7 (simple: 7)
    Pattern: moderate_continuous, Max cons√©cutif: 3 semaines
```

### 4. Tests statistiques

#### S√©lection automatique du test selon la taille d'√©chantillon
- **n ‚â• 30** : Test Z (proportions)
- **10 ‚â§ n < 30** : Test exact de Fisher
- **5 ‚â§ n < 10** : Test binomial exact
- **n < 5** : Pas de test (√©chantillon insuffisant)

#### Nouvelle colonne dans les r√©sultats
- **SCORING_METHOD** : 'weighted' ou 'simple' pour tra√ßabilit√©

## Output

### Table de sortie
**Nom** : `pt_z028_ar_{type_route}_validation_summary`  
**Localisation** : `mds_prod_gold_experiment.datasciences_dev`

### Structure DataFrame enrichie
| Colonne | Type | Description |
|:-------:|:----:|:------------|
| FAMILY | String | Famille de param√®tres analys√©e |
| WORST_ROUTE_STEPS | Integer | Nombre d'√©tapes dans la route |
| MATCHES | Integer | Nombre d'√©quipements probl√©matiques utilis√©s |
| WAFER_COUNT | Integer | Volume de wafers dans ce segment |
| BAD_RATE_PCT | Float | Taux de d√©faut observ√© (%) |
| BASELINE_PCT | Float | Taux moyen famille (%) |
| DELTA_PCT | Float | Impact relatif (+/-%) |
| P_VALUE | Float | Significativit√© statistique |
| **SCORING_METHOD** | String |'weighted' ou 'simple'|
| Processed_Date_Job | Date | Date d'ex√©cution |

## R√©sultats et interpr√©tation

### Exemple de sortie console
```
Traitement famille : NMOS-GO1-LVT
Utilisation du scoring pond√©r√© (50% r√©cence, 30% continuit√©, 20% persistance)

Worst route identifi√©e : 4 √©tapes retenues
  O_STRIP|STRIP_DRY -> SGAMA04 (Score pond√©r√©: 42.3, Pattern: strong_continuous)
  O_DEP_HK|DEP_HK -> TCENT11 (Score pond√©r√©: 38.1, Pattern: moderate_continuous)
  O_IMPL2|IMPL2_NWELL -> IVISM07 (Score pond√©r√©: 31.5, Pattern: sporadic)
  O_STRIP_ADJ|STRIP_DRY -> SGAMA14 (Score pond√©r√©: 28.9, Pattern: intermittent)

Baseline : 15.2%
  0/4 matches: 12.1% (-3.1%) [1234 wafers] p=0.023(Z)
  1/4 matches: 14.8% (-0.4%) [856 wafers] p=0.412(Z)
  2/4 matches: 18.7% (+3.5%) [423 wafers] p=0.008(Z)
  3/4 matches: 24.3% (+9.1%) [187 wafers] p<0.001(Fisher)
  4/4 matches: 31.2% (+16.0%) [52 wafers] p<0.001(Binomial)
```

### Comparaison weighted vs simple

| Aspect | simple | weighted |
|:------:|:-------------:|:---------------:|
| **M√©trique principale** | Somme simple (WEEK_SUM) | Score pond√©r√© (WEIGHTED_SCORE) |
| **R√©cence** | Non consid√©r√©e | 70% du score (d√©croissance exp.) |
| **Continuit√©** | Non √©valu√©e | 20% du score (bonus quadratique) |
| **√âquipement ancien corrig√©** | Reste prioritaire | Score fortement r√©duit |
| **Probl√®me r√©cent √©mergent** | Peut √™tre ignor√© | D√©tect√© rapidement |
| **Pattern analysis** | Absent | Classification automatique |

### Crit√®res de validation r√©ussie

#### Validation quantitative
**Corr√©lation positive** : Plus de matches ‚Üí taux d√©faut plus √©lev√©  
**Significativit√© statistique** : p-value < 0.05 pour segments critiques  
**Volume suffisant** : >50 wafers pour robustesse  
**Pattern coh√©rent** : √âquipements avec patterns 'continuous' prioris√©s  

#### Validation qualitative
**R√©cence confirm√©e** : Les probl√®mes identifi√©s sont actuels  
**Continuit√© v√©rifi√©e** : Pas de fausses alertes sur pics isol√©s  
**Actionnable** : Focus sur ce qui peut √™tre corrig√© maintenant  

## Impact

### 1. **Priorisation optimis√©e**
- Focus sur les probl√®mes **actuels** vs historiques
- D√©tection rapide des **d√©rives √©mergentes**
- √âlimination du **bruit** (pics isol√©s non significatifs)

### 2. **ROI maintenance**
- Interventions sur √©quipements **vraiment probl√©matiques**
- √âvite les actions sur probl√®mes **d√©j√† r√©solus**

### 3. **Tra√ßabilit√© compl√®te**
- Historique des scores et patterns
- √âvolution temporelle des probl√®mes track√©e

### 4. **Adaptabilit√©**
Les poids peuvent √™tre ajust√©s selon le contexte :
```python
# Process tr√®s stable ‚Üí Focus continuit√©
validate_routes(..., recency_weight=0.3, continuity_weight=0.6)

# Process en √©volution ‚Üí Focus r√©cence
validate_routes(..., recency_weight=0.8, continuity_weight=0.1)
```

# Conclusion Global


