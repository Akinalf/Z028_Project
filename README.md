# Z028_Project : Documentation Technique

## Vue d'ensemble m√©tier
- **Objectif** : Trouver la pire/meilleur route de process du debut jusqu'au PT intermediare
- **Techno** : [Z028]
- **Mesures de succ√®s** : Validation metier + reproductibilit√©e 

## Architecture technique
- **Technologies** : Spotfire, python, Databricks, pySpark, SQL
- **Ressources cluster** : [Voir Section Driver](#DriverNode)




# √âtat de l'Art : Optimisation des Routes de Process

## 1. Probl√©matique et Contexte 

### 1.1 D√©finition du probl√®me
L'optimisation des routes de processus (de semi-conducteurs) vise √† identifier les s√©quences d'√©quipements et d'√©tapes qui maximisent le rendement (yield) et et par consequent minimisent les d√©fauts. Une "route" repr√©sente le chemin exact qu'un lot/wafer suit √† travers les diff√©rentes etapes de fabrication.

### 1.2 Enjeux industriels
Dans le cadre de la technologie Z028 au cours de la route jusqu'au PT intermediaire on retrouve:
- **Complexit√© des fabs** : 134 op√©rations, 222 √©tapes, 1 a 5 √©quipements par √©tape
- **Impact √©conomique** : 1% √† 2% d'am√©lioration du yield serait non negligable
- **Variabilit√© √©quipements** : Performances diff√©rentes selon l'√©quipement choisi pour chaque √©tape
- **Contraintes temps r√©el** : D√©cisions de routage n√©cessaires en continu

## 2. Approches Algorithmiques pour l'Optimisation de Routes

### 2.1 Approches de Data Mining

#### 2.1.1 R√®gles d'Association (Approche retenue)
**Principe** : Identifier les patterns fr√©quents entre √©quipements et r√©sultats qualit√©.

APRIORI : "Si ETCH-XXX01 ET LITHO-XXX2 alors 89% chance d√©faut"
‚Üí Explication claire et actionnable

FP-Growth : R√©sultat identique mais processus "bo√Æte noire"  
‚Üí Plus difficile √† expliquer aux experts m√©tier

Volume Donn√©es vs Performance R√©elle
l'approche fen√™tre glissante 12 semaines change la donne :
|Algorithme|Dataset Complet (50M)|Fen√™tre 12 sem (~4M)|Verdict|
|----------|---------------------|--------------------|-------|
|APRIORI|Lent (~45+ min)|Acceptable (~4.2 min)|Optimal|
|FP-Growth|Rapide (~12 min)|Tr√®s rapide (~1.8 min)|Excessif|

**Algorithmes principaux** :
- **APRIORI** (Agrawal & Srikant, 1994)
  - ‚ÜóÔ∏è Avantages : Simplicit√©, interpr√©tabilit√© des r√®gles
  - ‚ÜóÔ∏è Adapt√© : Donn√©es cat√©goriques (√©quipements), relation claire cause-effet
  - ‚ùå Limitations : Performance sur gros volumes, scan multiple base de donn√©es

- **FP-Growth** (Han et al., 2000)
  - ‚ÜóÔ∏è Avantages : Performance sup√©rieure, un seul scan base de donn√©es
  - ‚ÜóÔ∏è Adapt√© : Gros volumes manufacturing data
  - ‚ùå Limitations : Consommation m√©moire, moins intuitif

- **Prefix Span** (Pei et al., 2001)
  - ‚ÜóÔ∏è Avantages : Prise en compte s√©quences temporelles
  - ‚ÜóÔ∏è Adapt√© : Routes s√©quentielles dans manufacturing
  - ‚ùå Limitations : Complexit√© algorithmique √©lev√©e


#### 2.1.2 Market Basket Analysis Adapt√©
**Principe** : Transposition des techniques retail vers manufacturing.
- "Produits" = √âquipements utilis√©s
- "Transactions" = Lots de wafers
- "R√®gles" = Si √©quipement A alors probabilit√© Wafer BAD √©lev√©e

### 2.2 Approches Machine Learning

#### 2.2.1 Apprentissage Supervis√© sur Donn√©es Continues
**Algorithmes test√©s** :
- **Random Forest** : Robuste aux outliers, importance variables
- **Gradient Boosting** : Performance √©lev√©e, gestion de la non-lin√©arit√©s
- **SVM** : Efficace pour dimensions √©lev√©es

**Limitations identifi√©es** :
- Variables continues (temp√©ratures, pressions) moins discriminantes que choix √©quipements
- Perte d'information causale directe √©quipement‚Üíd√©faut
- Complexit√© interpr√©tation pour experts manufacturing
- Dimensionalit√© trop √©lev√©e

#### 2.2.2 Apprentissage Supervis√© sur Donn√©es Cat√©goriques
**Algorithmes test√©s** :
- **R√©gression Logistique** : Baseline interpretable
- **R√©gression Binomiale N√©gative** : Gestion de la surdispersion
- **Classification Naive Bayes** : Rapide, requiert peu de parametres

**Avantages** :
- Probabilit√©s pr√©diction directement utilisables
- Variables cat√©goriques = √©quipements (mapping naturel)

**Limitations** :
- Hypoth√®ses statistiques forte (ind√©pendance, distribution)
- Difficult√© capture interactions complexes √©quipements
- Dimensionalit√© trop √©lev√©e

#### 2.2.3 Deep Learning / R√©seaux de Neurones
**Approches envisag√©es** :
- **LSTM** : S√©quences temporelles de routes
- **CNN** : Patterns spatiaux sur wafers

**Raisons rejet** :
- "Trop de combinaisons pour l'algorithme" ‚Üí Explosion combinatoire
- 134 op√©rations √ó moyens 3-4 √©quipements/op√©ration = ~10^200 routes possibles
- Manque donn√©es √©tiquet√©es pour entra√Ænement deep learning
- Complexit√© d√©ploiement et maintenance en production

### 2.3 M√©thodes d'Optimisation Combinatoire

#### 2.3.1 Algorithmes G√©n√©tiques
- **Principe** : √âvolution d'une population de routes compl√®tes vers l'optimum yield par s√©lection, croisement et mutation successives. Chaque route (chromosome) repr√©sente une s√©quence compl√®te d'√©quipements pour les 134 op√©rations.
- **Applications** : Optimisation simultan√©e de s√©quences compl√®tes d'√©quipements (Kumar et al., 2006).
- **Limitations** : Explosion combinatoire, Solutions optimales sans justification causale

## 3. Techniques de Validation Routes Manufacturing

### 3.1 Validation (Approche retenue)
**Principe** : Comparaison performance routes identifi√©es sur donn√©es historiques.

**M√©thode** :
- R√©cup√©ration wafers ayant suivi exactement la "golden/worst route"
- Comparaison taux GOOD/BAD vs wafers routes alternatives
- Test significativit√© statistique (Chi-2, Fisher exact test)

**Avantages** :
- Donn√©es r√©elles, repr√©sentatives dans les conditions de production
- Validation robuste si volume suffisant
- Interpr√©tation directe pour experts m√©tier

### 3.3 Validation Exp√©rimentale
- **Principe** : Test contr√¥l√© routes identifi√©es sur lots d√©di√©s.
- **Avantages** : Validation d√©finitive, conditions r√©elles
- **Limitations** : Co√ªt √©lev√©, risque production, d√©lais longs

### 3.4 Cross-Validation Temporelle
- **Principe** : Entra√Ænement sur p√©riode N, validation p√©riode N+1.
- **Application** : Fen√™tre glissante 12 semaines avec validation 4 semaines suivantes
- **Robustesse** : D√©tection d√©rive performance √©quipements

## 4. Comparaison et Justification Choix Techniques

### 4.1 Matrice de D√©cision

| Crit√®re | R√®gles Association | ML Supervis√© | Deep Learning | Optimisation Combinatoire |
|:---------:|:-------------------:|:--------------:|:---------------:|:--------------:|
| **Interpr√©tabilit√©** |  üü©Excellente | üü®Moyenne |  üü•Faible | üü®Moyenne |
| **Performance** | üü®Moyenne |üü©Bonne |üü©Excellente | üü©Bonne |
| **Temps d√©veloppement** |üü©Court | üü®Moyen |  üü•Long | üü•Long |
| **Robustesse donn√©es** |üü©Bonne | üü®Moyenne |  üü•Faible |üü© Bonne |
| **D√©ploiement prod** |üü©Simple | üü®Moyen | üü•Complexe | üü®Moyen |
| **Expertise requise** | üü®Moyenne |üü©Standard | üü•√âlev√©e | üü•√âlev√©e |

### 4.2 Justification Choix Final

**R√®gles d'Association (APRIORI) retenues pour** :
- **Interpr√©tabilit√© essentielle** : Les experts m√©tier doivent pouvoir comprendre facilement les recommandations d‚Äô√©quipements.
- **Donn√©es adapt√©es** : Les variables cat√©goriques (types d‚Äô√©quipements) sont naturellement compatibles avec cet algorithme.
- **Validation simple** : Les r√®gels g√©n√©r√©es sont facilement v√©rifiable √† partir des donn√©es historiques 
- **D√©ploiement rapide** : L‚Äôalgorithme est simple √† mettre en ≈ìuvre et √† maintenir.

**Machine Learning √©cart√© pour** :
- La complexit√© d'interpr√©tation est trop √©lev√©e pour une prise de d√©cision en production.
- Le gain de performance est insuffisant face au co√ªt de d√©veloppement et de maintenance.
- Risque important de surapprentissage (overfitting) d√ª au bruit pr√©sent dans les donn√©es de fabrication.

**Deep Learning √©cart√© pour** :
- Explosion combinatoire li√©e au nombre tr√®s √©lev√© de routes possibles.
- Manque donn√©es (wafer) en production pour un apprentissage efficace.
- Complexit√© importante en termes d‚Äôinfrastructure et d‚Äôexpertise n√©cessaire.

## 5. Bibliographie des algorythmes

**R√®gles d'Association Manufacturing** :
- Kusiak, A. (2000). "Rough set theory in manufacturing". *International Journal of Production Research*, 38(18), 4349-4364.
- Chen, F., et al. (2008). "Association rule mining for defect detection in semiconductor manufacturing". *IEEE Transactions on Semiconductor Manufacturing*, 21(3), 398-409.

**Optimisation Routes Semi-conducteurs** :
- M√∂nch, L., et al. (2013). "Production planning and control for semiconductor wafer fabrication facilities". *Springer*.
- Kumar, P., et al. (2006). "Genetic algorithm approach for scheduling in a complex manufacturing system". *International Journal of Advanced Manufacturing Technology*, 30(7-8), 682-692.


## 6. Perspectives et Am√©liorations Futures

### 6.1 Hybridation des approches
- Combinaison des r√®gles d'association avec des m√©thodes ML pour am√©liorer la pr√©cision et la robustesse des recommandations.

### 6.2 Temps R√©el et Streaming
- Adaptation Kafka pour donn√©es √©quipements en temps r√©el
- Mise √† jour incr√©mentale des r√®gles d'association



## Impl√©mentation code d√©taill√©

---
Pipeline Unity Catalog
---
```mermaid
flowchart TD
    %% Unity Catalog avec les 4 tables en ligne
    subgraph UC ["Unity Catalog"]
        A[("pt_klf")]
        B[("pt_kdf_lot")] 
        C[("pt_kdf_parameter")]
        D[("v_leh_fe_std")]
    end
    
    %% Script principal
    E["üììDataPrep.py"]
    
    %% Fichier CSV
    F[\"df_PTM2_param_<br/>family_parameter.csv"\]
    
    %% Tables g√©n√©r√©es et Fichier CSV 
    G[("pt_z028_input_<br/>bad_for_ar")]
    H[("pt_z028_input_<br/>good_for_ar")]
    I[\"df_family_ref.csv"\]
    
    %% Scripts d'analyse
    J["üììAR_FAMILIES_EQPT"]
    
    %% Tables r√©sultats
    K[("Pt_z028_ar_bad<br/>route_result")]
    L[("Pt_gor2_ar_good<br/>route_result")]
    
    %% Connexions principales
    UC --> E
    F --> E
    I --> E

    E ~~~ I 
    E --> G
    E --> H
    

    I --> J
    G --> J
    H --> J

    J --> K
    J --> L
    
    %% L√©gende des formes
    subgraph legend ["üìñ L√©gende"]
        direction LR
        LT[("Tables")]
        LS["üììScripts"]
        LC[\"CSV"\]
    end
    
    %% Styles avec couleurs distinctes
    classDef cylinder fill:#e1f5fe,stroke:#0277bd,stroke-width:3px
    classDef script fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef csv fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef subgraphStyle fill:#fafafa,stroke:#666,stroke-width:1px
    classDef subgraphCatalog fill:transparent,stroke:#666,stroke-width:1px

    class A,B,C,D,G,H,L,K cylinder
    class E,J script
    class F csv
    class I csv
    class legend subgraphStyle
    class UC subgraphCatalog
    class LT cylinder
    class LS script
    class LF parquet
    class LC csv
```

---

#  Job et Pipeline Databricks

## **Vue d'ensemble du Job**

###  **Principe cl√© :**
- **Un seul notebook** ‚Üí Deux comportements diff√©rents
- **Param√®tre `type_route`** ‚Üí D√©termine le flux de donn√©es
- **Logique conditionnelle** ‚Üí `"good"` vs `"bad"` routes
- **Planification** ‚Üí Execution par p√©riode.

---


| Phase | Processus | Dur√©e |
|-------|-----------|--------|
| **Phase 1** | Data Prep | 6 min |
| **Phase 2** | APRIORI | 56 min |
| **Phase 3** | Validation | 30 sec |


# **Job Principal : `PT_Z028_Worst_Route`**

## Cluster Z028_Job_Cluster
<a id="DriverNode"></a>
## Configuration des Nodes

<table>
<tr>
<td width="50%" align="center">


### **Driver Node**
**Type :** Standard_D5s_v2
**RAM :** 112 GB
**Cores :** 16
**Quantit√© :** 1

</td>
<td width="50%" align="center">

### **Worker Nodes**
**Type :** Standard_D4ds_v5  
**RAM :** 32 GB par node
**Cores :** 4 par node
**Quantit√© :** 8 (Spot instances)

*Les Spot Instances dans Databricks sont des machines virtuelles √† prix r√©duit, mais avec moins de garanties de disponibilit√©.*
</td>
</tr>
</table>

## Ressources Totales

<div align="center">

| **RAM Total** | **Cores Total** | **Nodes Total** |
|:----------------:|:------------------:|:-------------------:|
| **64-256 GB** | **16-64 Cores** | **9 Nodes** |

---

### **Performance**

| T√¢che | Dur√©e | Notes |
|:-------:|:-------:|:-------:|
| **Data_Preparation** | 10 min | Traitement Unity Catalog |
| **AR_BAD/GOOD** | 46 min | APRIORI fen√™tre glissante |
| **Validation** | 6 min | Tests statistiques |
| **Total Pipeline** | **Auto-scaling** |  |

### **Orchestration & D√©pendances**

```mermaid
graph TD
    A[Data_Preparation] --> B[AR_BAD]
    A --> C[AR_GOOD] 
    B --> D[AR_BAD_VALIDATION]
    C --> E[AR_GOOD_VALIDATION]
    
    style A fill:#667eea
    style B fill:#f093fb  
    style C fill:#f093fb
    style D fill:#4facfe
    style E fill:#4facfe
```
</div>

### Planification
|**Fr√©quence** |**D√©clencheur**|**Timeout**|
|---------------------------------------|------------------------|---------------------|
| Hebdomadaire (chaque lundi 02:00 UTC) | Cron `58 30 4 ? * Mon` | 2h maximum par job  |


### Avantages Architecture Databricks

####  R√©utilisabilit√© maximale

- **M√™me notebook** `AR_FAMILIES_EQPT`  
- **Param√®tre** `type_route` change le comportement  
- **DRY Principle** respect√©  

####  Parall√©lisation intelligente

- **AR_BAD** et **AR_GOOD** en parall√®le  
- **Validation** en s√©quence pour coh√©rence  
- **Optimisation ressources** automatique  


####  Monitoring int√©gr√©

- **M√©triques temps r√©el** par t√¢che  
- **Notifications email** en cas d'√©chec  
- **Logs centralis√©s** pour debug  

---
####  Scalabilit√©


  


|**Auto-scaling cluster** |**Photon engine**|**Adaptive Query Execution**|
|---------------------|-----------------------|--------------|
|  selon la charge  | pour performance SQL | optimis√© |


---


## **Principe de Param√©trage**

### **Notebook unique : `AR_FAMILIES_EQPT`**

| Param√®tre | Valeur | Comportement |
|:------------:|:--------:|:-------------------------------:|
| `type_route` | `"good"` | Lit/√âcrit dans **Golden Route** |
| `type_route` | `"bad"` | Lit/√âcrit dans **Worst Route** |

### **Logique dynamique dans le code :**
```python
# Dans le notebook AR_FAMILIES_EQPT
type_route = dbutils.widgets.get("type_route")

# Pour import
df_EQPT_spark = spark.sql(f"""
    SELECT *
    FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_input_{type_route.lower()}_for_ar
    WHERE T84_TEST_DATE BETWEEN DATE_SUB(CURRENT_DATE(), 365) AND CURRENT_DATE()
""")
# Et export
    create_or_update_table(spark.createDataFrame(sparkfinal_merged_df),
    f"mds_prod_gold_experiment.datasciences_dev.pt_z028_ar_{type_route.lower()}_route_results")
```

---

## **Avantages de cette approche**

### **R√©utilisabilit√©**

- **Un seul code source** √† maintenir
- **Logique m√©tier identique** pour les deux cas
- **√âvite la duplication** de code

### **Maintenabilit√©**

- **Changements centralis√©s** dans un seul notebook
- **Coh√©rence garantie** entre les deux flux
- **Tests simplifi√©s**

### **Flexibilit√©**
- **Facilement extensible** (ajout de nouveaux types)
- **Configuration par param√®tres**
- **Orchestration Databricks native**

---



</div>


# Phase 1 : DATA_PREP.py - Rapport d'√©tat des lieux

## Vue d'ensemble

Le script `DATA_PREP.py` constitue la phase de pr√©paration des donn√©es du projet Z028. Il traite les donn√©es brutes du PT intermediaire pour produire les tables n√©cessaires √† l'analyse des r√®gles d'association.

*Note technique : Une version parall√®le de ce script existe avec des clauses WHERE √©tendues √† 365 jours (au lieu des filtres standards). Cette version a servi √† l'initialisation initiale des tables de r√©f√©rence avec un historique complet d'une ann√©e de donn√©es de production.*

### 1. Extraction SQL depuis Unity Catalog

#### LOT_LIST_INFORMATION_DF - Liste des lots √©ligibles
```sql
SELECT pt_kdf_lot_number AS LOT, 
       pt_kdf_cam_location AS LOCATION, 
       pt_kdf_product_code AS PRODUCT,
       pt_kdf_test_start_datetime AS START_DATE,
       pt_kdf_test_end_datetime AS END_DATE,
       pt_kdf_spec_name AS SPEC_NAME,
       pt_kdf_spec_version AS SPEC_VERSION

FROM sem1.pt_kdf_lot_normalized 
WHERE pt_kdf_cam_location = 'M2SICN-ADT02' 
  AND fab_name = 'CROLLES 300'
  AND LEFT(pt_kdf_product_code, 5) = 'KVB98'
  AND pt_kdf_test_end_datetime >= DATE_SUB(CURRENT_DATE(), 7)
  AND length(pt_kdf_lot_number) <= 7
```
**Filtres appliqu√©s** :
- **Localisation** : M2SICN-ADT02 (√©quipement de test sp√©cifique)
- **Fab** : CROLLES 300 uniquement
- **Produit** : Code produit commen√ßant par 'KVB98' (technologie Z028)
- **P√©riode** : 365 derniers jours
- **Format lot** : Maximum 7 caract√®res

#### df_parameter_info - Donn√©es des param√®tres
```sql
SELECT
    pt_kdf_lot_number AS LOT,
    pt_kdf_cam_location AS T84_LOCATION,
    pt_kdf_parameter_id AS PARAMETER,
    pt_kdf_parameter_value AS PARAMETER_VALUE,
    pt_kdf_test_start_datetime AS START_DATE,
    pt_kdf_test_end_datetime AS END_DATE,
    pt_kdf_wafer_number AS WAFER,
    tech_lz_folder_source_id AS FAB,
    pt_kdf_spec_name AS SPEC_NAME,
    pt_kdf_spec_version AS SPEC_VERSION,
    pt_kdf_site_name AS SITE_NUMBER,
    pt_kdf_site_is_last_pattern AS IS_LAST_PATTERN,
    MAX(pt_kdf_test_end_datetime) OVER (PARTITION BY pt_kdf_lot_number) AS MAX_TEST_DATE

FROM sem1.pt_kdf_parameter_normalized

WHERE pt_kdf_cam_location = 'M2SICN-ADT02' 
    AND fab_name = 'CROLLES 300' 
    AND pt_kdf_test_end_datetime >= DATE_SUB(CURRENT_DATE(), 7)
    AND length(pt_kdf_lot_number) <= 7
    AND pt_kdf_lot_number IN (SELECT LOT FROM LOT_LIST_INFORMATION_DF)
    AND pt_kdf_parameter_id IN (SELECT PARAMETER FROM df_PTM2_param_family_Parameter)
```
**Optimisations SQL** :
- **Window function** : MAX(test_end_datetime) OVER (PARTITION BY lot) pour identifier le dernier test
- **Jointure implicite** : IN clause avec LOT_LIST_INFORMATION_DF 
- **Filtrage param√®tres** : Seulement les param√®tres d√©finis dans df_PTM2_param_family_Parameter

####  df_Value_info - Limites et sp√©cifications
```sql
SELECT
    pt_klf_spec_name AS SPEC_NAME,
    pt_klf_spec_version AS SPEC_VERSION,
    pt_klf_parameter_id AS PARAMETER,
    pt_klf_validity_limit_lower_bound AS LVL,
    pt_klf_validity_limit_upper_bound AS UVL,
    pt_klf_spec_limit_lower_bound AS LSL,
    pt_klf_spec_limit_upper_bound AS USL,
    pt_klf_parameter_category AS PARAMETER_TYPE,
    pt_klf_parameter_target AS PARAMETER_TARGET

FROM sem1.pt_klf_normalized
    
WHERE
    pt_klf_parameter_id in (SELECT PARAMETER FROM df_PTM2_param_family_Parameter)
    AND (pt_klf_parameter_category in ('GY', 'GR', 'KR', 'KY'))
    AND pt_klf_spec_name = "C28SOIM2SICN"
```
**Limites d√©finies** :
- **LVL/UVL** : limites de validit√©
- **LSL/USL** :limites de sp√©cification
- **Cat√©gories** : GY, GR, KR, KY (types de param√®tres qualit√©)
- **Spec** : C28SOIM2SICN 

#### df_lot_history - Historique des √©quipements
```sql
select 
  leh_fe_std_lot_id as LOT
  ,leh_fe_std_operation_name as OPERATION
  ,leh_fe_std_operation_description as OPERATION_DESCRIPTION
  ,leh_fe_std_step_name as STEP
  ,leh_fe_std_equipment_id as EQUIPMENT
  ,leh_fe_std_lot_step_start_datetime as STEP_START_DATE
  ,leh_fe_std_lot_step_end_datetime as STEP_END_DATE
  ,leh_fe_std_mes_product_name as PRODUCT
  ,leh_fe_std_route_name as ROUTE
  ,leh_fe_std_recipe_id as RECIPE_ID
from publication.v_leh_fe_std_normalized
where 
  leh_fe_std_route_name = 'Z028RR_14KLR_34LS_10M'
  AND leh_fe_std_lot_id IN (SELECT LOT FROM LOT_LIST_INFORMATION_DF)
  AND SUBSTR(leh_fe_std_equipment_id, 1, 1) <> 'X'
  AND INSTR(leh_fe_std_step_name, 'MEAS') = 0
```
**Filtres route** :
- **Route sp√©cifique** : Z028RR_14KLR_34LS_10M (route de r√©f√©rence Z028)
- **√âquipements valides** : Exclusion des √©quipements commen√ßant par 'X'
- **√âtapes process** : Exclusion des √©tapes de mesure ('MEAS')

### 2. Fichiers CSV de r√©f√©rence
- **Z028_DEFAULT_PROCESS_ROUTE.csv** : Route de processus par d√©faut (s√©parateur `;`)
- **Df_Family_Ref.csv** : R√©f√©rentiel des familles de param√®tres (s√©parateur `;`)

## Transformations principales

### 1. Calcul des rendements
- Jointure donn√©es test + sp√©cifications
- Calcul OOV/OOS par param√®tre ‚Üí Yield par famille
- Pivot des familles de param√®tres en colonnes

### 2. Traitement des √©quipements
- Filtrage des √©tapes avec √©quipements variables uniquement
- Calcul de l'ordre des √©tapes et rang des op√©rations
- Encodage cat√©goriel des combinaisons STEP-EQUIPMENT

### 3. Classification GOOD/BAD
- Application des seuils m√©tier par famille (ex: CONTACT < 0.98 ‚Üí BAD)
- Agr√©gation au niveau LOGICAL_ID + OPERATION + STEP

## Outputs
Deux tables stocker dans :
  ***mds_prod_gold_experiment.datasciences_dev***
- **pt_z028_input_bad_for_ar** : Table avec indicateur BAD
- **pt_z028_input_good_for_ar** : Table avec indicateur GOOD (inverse)

**Structure finale** : 1 ligne = 1 lot + 1 √©tape + m√©triques yield + classification + √©quipements encod√©s

‚Üí  **Pr√™t pour l'analyse des r√®gles d'association** dans AR_BAD.py


# Phase 2 : AR_FAMMILLIES_EQPT.py - Analyse des R√®gles d'Association

##  Objectif
Identifier les √©quipements probl√©matiques par famille de param√®tres en utilisant l'algorithme APRIORI sur des fen√™tres glissantes de 12 semaines.

## Donn√©es d'entr√©e
- **pt_z028_input_bad_for_ar** : Table de sortie de Data_Prep.py, dataset avec encodage √©quipements + indicateur BAD
- **Df_Family_Ref.csv** : R√©f√©rentiel familles de param√®tres

## Pipeline principal

### 1. Pr√©paration des donn√©es
- **Optimisation m√©moire** : Conversion dtypes (downcast integers/floats, cat√©gorisation strings)
- **Fen√™tres glissantes** : D√©coupage en p√©riodes de 12 semaines avec d√©calage hebdomadaire
- **Filtrage par famille** : S√©lection des √©tapes pertinentes selon le r√©f√©rentiel

### 2. Analyse APRIORI par √©tape
Pour chaque (OPERATION, STEP) :
- **Encodage** : Colonnes `STEP_EQPT_[STEP]-[EQUIPMENT]` + `BAD`
- **Filtrage fr√©quence** : Garder √©quipements pr√©sents >5% du temps
- **APRIORI** : Recherche itemsets fr√©quents (min_support=0.1)
- **R√®gles d'association** : Calcul confidence, lift, support
- **Filtrage cibl√©** : R√®gles avec cons√©quent = `BAD` uniquement

### 3. Scoring et ranking
- **Score composite** : `confidence √ó lift √ó support`
- **Ranking** : Classement des √©quipements par score d√©croissant
- **Fen√™tre glissante** : Application sur toutes les semaines

### 4. Agr√©gation temporelle
- **Pivot** : Semaines en colonnes, scores en valeurs
- **Ranking final** : Rang de chaque √©quipement par semaine et par √©tape


## Output
Deux tables stocker dans :
***mds_prod_gold_experiment.datasciences_dev***

- **pt_z028_ar_bad_route_results** : Resultats des regles d'associations pour chaque famille a travers les semaines.
- **pt_z028_ar_good_route_results** : Resultats des regles d'associations pour chaque famille a travers les semaines.
- **Structure** : FAMILY | OPERATION | STEP | EQPT | week_0 | week_1 | ... | week_n
- **Valeurs** : Rang de l'√©quipement (1 = le plus probl√©matique)

##  R√©sultat m√©tier
**Identification des √©quipements les plus corr√©l√©s aux d√©fauts par famille**, avec une √©volution temporelle pour d√©tecter les d√©rives.

‚Üí **Pr√™t pour la validation** dans VALIDATION_AR_FAMILLIES.py


# Phase 3 : VALIDATION_AR_FAMILIES - Validation des Routes Identifi√©es

## Objectif
Valider statistiquement les routes identifi√©es comme probl√©matiques ou bonnes dans la Phase 2 en comparant les performances r√©elles des wafers ayant suivi ces √©quipements.

## Param√©trage dynamique
Le script utilise le param√®tre `type_route` des widgets Databricks pour d√©terminer si on effectue l'analyse de la worst ou de la golden route :

```python
type_route = dbutils.widgets.get("type_route")  # "good" ou "bad"
```

## Donn√©es d'entr√©e

### 1. Donn√©es √©quipements (Fen√™tre 365 jours)
```python
df_EQPT_spark = spark.sql(f"""
    SELECT *
    FROM mds_prod_gold_experiment.datascent_dev.pt_z028_input_{type_route.lower()}_for_ar
    WHERE T84_TEST_DATE BETWEEN DATE_SUB(CURRENT_DATE(), 365) AND CURRENT_DATE()
""")
```

### 2. R√©sultats AR les plus r√©cents
```python
df_ar_result = spark.sql(f"""
    SELECT * 
    FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_input_bad_route_results 
    WHERE Processed_Date_Job = ( 
        SELECT MAX(Processed_Date_Job) FROM mds_prod_gold_experiment.datasciences_dev.pt_z028_input_bad_route_results 
    )
""")
```

## Pipeline de validation

### 1. Fonction `validate_routes` - Param√®tres cl√©s

#### Seuil de filtrage renforc√©
- **min_sum=6** : Seuil minimum pour les sommes des colonnes `week_*`
*un equipement doit etre pr√©sent au moins 6 fois pour etre pris en compte*  

**Justification** : √âlimine les √©quipements avec trop peu d'occurrences sur les fen√™tres glissantes
**Impact** : Focus sur les √©quipements r√©ellement probl√©matiques de fa√ßon r√©currente

#### Traitement des donn√©es
```python
routes, df_validation = validate_routes(df_ar_result, df_EQPT_spark, type_route, min_sum=6)
```

### 2. Processus de validation interne

#### √âtape 1 : Conversion et pr√©paration
- **Conversion Spark ‚Üí Pandas** pour optimiser les calculs complexes
- **Calcul WEEK_SUM** : Somme des occurrences par √©quipement sur toutes les semaines
- **Filtrage min_sum** : `df_ar[df_ar['WEEK_SUM'] >= 6]`

#### √âtape 2 : Construction des worst/best routes
- **D√©duplication par OP_STEP** : Un seul √©quipement par √©tape (celui avec le WEEK_SUM max)
- **Construction OP_STEP** : Concat√©nation `OPERATION + '|' + STEP`
- **Route finale** : Liste des √©quipements les plus r√©currents par famille

#### √âtape 3 : Validation sur donn√©es r√©elles
- **Matching wafers** : Identification des lots ayant utilis√© ces √©quipements
- **Comptage matches** : Nombre d'√©tapes "worst/best" par wafer
- **Calcul baseline** : Taux moyen sur l'ensemble de la population

### 3. Algorithme de validation d√©taill√©

#### Processus par famille
1. **Filtrage famille** : S√©lection des donn√©es pour une famille sp√©cifique
2. **Application seuil** : Conservation des √©quipements avec `WEEK_SUM >= min_sum`
3. **S√©lection best equipment** : Par OP_STEP, garder l'√©quipement avec le WEEK_SUM maximum
4. **Merge avec donn√©es lot** : Jointure sur OP_STEP pour identifier les matches
5. **Agr√©gation wafer** : Comptage des matches par LOGICAL_ID


### 4. M√©triques de validation

#### Analyse gradu√©e par nombre de matches
Pour chaque famille, calcul des taux selon le nombre d'√©quipements probl√©matiques utilis√©s :
- **0 matches** : Wafers sans √©quipement identifi√©
- **1-N matches** : Impact proportionnel au nombre d'√©quipements utilis√©s
- **Validation r√©ussie** : Corr√©lation positive matches ‚Üî taux de d√©faut

#### M√©triques produites
- **BASELINE_PCT** : Taux moyen de la famille
- **BAD_RATE_PCT** : Taux par niveau de matches
- **DELTA_PCT** : √âcart par rapport √† la baseline
- **WAFER_COUNT** : Volume statistique par segment


## Output final

### Table de sortie
**Nom** : `pt_z028_ar_{type_route}_validation_summary`  
**Mode** : Cr√©ation/Mise √† jour automatique  
**Localisation** : `mds_prod_gold_experiment.datasciences_dev`

### Structure DataFrame de sortie
| Colonne | Type | Description |
|:-------:|:----:|:------------|
| FAMILY | String | Famille de param√®tres analys√©e |
| WORST_ROUTE_STEPS | Integer | Nombre d'√©tapes dans la route identifi√©e |
| MATCHES | Integer | Nombre d'√©quipements identifi√©s utilis√©s |
| WAFER_COUNT | Integer | Volume de wafers dans ce segment |
| BAD_RATE_PCT | Float | Taux de d√©faut observ√© (%) |
| BASELINE_PCT | Float | Taux moyen famille (%) |
| DELTA_PCT | Float | Impact relatif (+/-%) |
| Processed_Date_Job | Date | Date d'ex√©cution du job |

## R√©sultat m√©tier

### Validation quantitative
- **Seuil renforc√© (min_sum=6)** : Focus sur les √©quipements r√©ellement r√©currents
- **Donn√©es sur 365 jours** : Robustesse statistique maximale
- **Analyse gradu√©e** : Impact proportionnel confirm√©
- **Tra√ßabilit√© compl√®te** : Historisation des validations successives

### Exemple de r√©sultat console
```
Traitement famille : CONTACT

Worst route identifi√©e : 4 √©tapes
  OP123|STEP456 -> EQPT789 (WEEK_SUM: 8)
  OP124|STEP457 -> EQPT790 (WEEK_SUM: 6)
  OP125|STEP458 -> EQPT791 (WEEK_SUM: 7)
  OP126|STEP459 -> EQPT792 (WEEK_SUM: 9)

Baseline : 15.2%
  0/4 matches: 12.1% (-3.1%) [1234 wafers]
  1/4 matches: 14.8% (-0.4%) [856 wafers]
  2/4 matches: 18.7% (+3.5%) [423 wafers]
  3/4 matches: 24.3% (+9.1%) [187 wafers]
  4/4 matches: 31.2% (+16.0%) [52 wafers]
```

### Interpr√©tation des r√©sultats

#### **Validation r√©ussie si :**
- **Corr√©lation positive** : Plus de matches ‚Üí taux BAD plus √©lev√©
- **Deltas significatifs** : √âcarts ~>5% par rapport baseline
- **Volume suffisant** : ~>50 wafers par segment pour robustesse statistique


### Impact business
1. **Priorisation actions** : Focus sur les familles avec des deltas √©lev√©s
4. **Feedback process** : Validation, efficacit√©, corrections appliqu√©es.

# Conclusion Global


